#%%
#Primer paso: importar las librerías necesarias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import statsmodels.formula.api as smf
from statsmodels.iolib.summary2 import summary_col
import scipy.stats as st
from statsmodels.sandbox.stats.runs import cochrans_q
from sklearn.impute import KNNImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OrdinalEncoder
import os 

#%%
#Segundo Paso: cargar el archivo
df = pd.read_csv("C:/Users/userx/Downloads/miencuesta.csv")
def cargar_datos(ruta):
    try:
        if not os.path.exists(ruta):
            raise FileNotFoundError(f"No se encontró el archivo: {ruta}")
        _, extension = os.path.splitext(ruta)
        extension = extension.lower().strip()
        if extension == ".csv":
            df = pd.read_csv(ruta, encoding="utf-8")
        elif extension in [".xls", ".xlsx"]:
            df = pd.read_excel(ruta)
            ruta_csv = ruta.replace(extension, ".csv")
            df.to_csv(ruta_csv, index=False, encoding="utf-8")
            print(f"Archivo Excel convertido y guardado como CSV → {ruta_csv}")
        elif extension == ".json":
            df = pd.read_json(ruta)
            ruta_csv = ruta.replace(extension, ".csv")
            df.to_csv(ruta_csv, index=False, encoding="utf-8")
            print(f"Archivo JSON convertido y guardado como CSV → {ruta_csv}")
        elif extension == ".txt":
            df = pd.read_csv(ruta, sep="\t", encoding="utf-8")
            ruta_csv = ruta.replace(extension, ".csv")
            df.to_csv(ruta_csv, index=False, encoding="utf-8")
            print(f"Archivo TXT convertido y guardado como CSV → {ruta_csv}")
        else:
            raise ValueError(f"Formato no soportado: {extension}")
        print(f"Archivo cargado correctamente ({extension}) → {ruta}")
        print(f"   Filas: {len(df)} | Columnas: {len(df.columns)}")
        return df

    except FileNotFoundError as e:
        print(f"Error: {e}")
    except pd.errors.EmptyDataError:
        print("Error: el archivo está vacío.")
    except pd.errors.ParserError:
        print("Error: formato de archivo incorrecto o corrupto.")
    except ValueError as e:
        print(f"Error: {e}")
    except Exception as e:
        print(f"Error inesperado al cargar el archivo: {e}")
    return None

df.columns = (
            df.columns
              .str.strip()
              .str.lower()
              .str.replace(" ", "_")
              .str.replace(r"[^a-z0-9_]", "", regex=True)
        )
columnas_requeridas = [
            "fecha", "encuesta", "estrato", "sexo", "edad", "nivel_educativo", "cantidad_de_integrantes_en_el_hogar", "imagen_del_candidato", "voto", "voto_anterior"
        ]
try:
    faltantes = [col for col in columnas_requeridas if col not in df.columns]
    if faltantes:
        raise ValueError(f"Faltan columnas requeridas en el archivo: {faltantes}")

ruta = "C:/Users/userx/Downloads/miencuesta.csv"
df = cargar_datos(ruta)
if df is not None and validar_columnas(df, columnas_requeridas):
    df["Fecha"] = pd.to_datetime(df["Fecha"], errors="coerce")
    print("DataFrame listo para procesamiento (imputación, ponderación, tracking).")
else:
    raise SystemExit("No se puede continuar: error en carga o columnas.")

#%%
#Tercer paso: manipular los valores faltantes
df = df[~df[['voto', 'imagen_del_candidato']].isna().all(axis=1)] #si faltan las 2 variables claves, descartar encuesta
df = df[df['edad'] >= 16] #si alguien tiene menos de 16, se borra la encuesta ya que no puede votar
df = df[~df['encuesta'].duplicated()] #si está duplicado, borrarlo
def hot_deck(df, target_col, ref_cols):  # Bloque genérico para imputar con hot-deck
    df = df.copy()
    known = df[df[target_col].notna()]
    missing = df[df[target_col].isna()]
    for idx in missing.index:
        caso = df.loc[idx, ref_cols]
        dist = pd.Series(0, index=known.index, dtype=float)
        for ref in ref_cols:
            if np.issubdtype(df[ref].dtype, np.number):
                dist += abs(known[ref] - caso[ref]).fillna(1)
            else:
                dist += (known[ref] != caso[ref]).fillna(True).astype(int)
        if dist.isna().all():
            continue  # si todo fue NaN, paso al siguiente
        donante = known.loc[dist.idxmin(), target_col]
        df.loc[idx, target_col] = donante
    return df
df['fecha'] = df['fecha'].interpolate() 
df = df.dropna(subset=['estrato'])
df = df.dropna(subset=['sexo'])
df = df.dropna(subset=['edad'])
df['nivel_educativo'] = df['nivel_educativo'].fillna('Desconocido')
df['cantidad_de_integrantes_en_el_hogar'] = df['cantidad_de_integrantes_en_el_hogar'].fillna('Desconocido')
df = hot_deck(df, target_col='imagen_del_candidato', ref_cols=['edad', 'sexo', 'estrato', 'voto','nivel_educativo','voto_anterior'])
df = hot_deck(df, target_col='voto', ref_cols=['edad', 'sexo', 'estrato', 'imagen_del_candidato','nivel_educativo','voto_anterior'])
df = hot_deck(df, target_col='voto_anterior', ref_cols=['edad', 'sexo', 'estrato', 'imagen_del_candidato','nivel_educativo','voto'])
df

# %%
#Cuarto Paso: definir la ventana
df = df.sort_values('fecha')
conteo_por_dia = df['fecha'].value_counts()
print(conteo_por_dia)
if (conteo_por_dia >= 750).all():
    df['Ventana'] = df['fecha']
else:
    df['Ventana'] = df['fecha'].dt.to_period('W').astype(str)

# %%
#Quinto Paso: pesos por ventana
bins = [15, 29, 44, 59, 120]
labels = ['16–29', '30–44', '45–59', '60+']
df['Grupo_Edad'] = pd.cut(df['edad'], bins=bins, labels=labels)
poblacion = pd.DataFrame({
    'sexo': ['Masculino','Masculino','Masculino','Masculino',
             'Femenino','Femenino','Femenino','Femenino'],
    'Grupo_Edad': ['16–29','30–44','45–59','60+']*2,
    'Prop_SE': [0.142, 0.133, 0.108, 0.093,
                0.145, 0.137, 0.117, 0.125]
})
prov = pd.DataFrame({
    'Provincia': [
        'Ciudad Autónoma de Buenos Aires','Buenos Aires','Catamarca','Chaco','Chubut','Córdoba',
        'Corrientes','Entre Ríos','Formosa','Jujuy','La Pampa','La Rioja','Mendoza','Misiones',
        'Neuquén','Río Negro','Salta','San Juan','San Luis','Santa Cruz','Santa Fe',
        'Santiago del Estero','Tierra del Fuego','Tucumán'
    ],
    'Poblacion': [
        3121707,17523996,429562,1129606,592621,3840905,
        1212696,1425578,607419,811611,361859,383865,2043540,1278873,
        710814,750768,1440672,822853,542069,337226,3544908,
        1060906,185732,1731820
    ]
})
prov['Prop_Prov'] = prov['Poblacion'] / prov['Poblacion'].sum()
p = poblacion.assign(key=1).merge(prov.assign(key=1), on='key').drop(columns='key')
p['Prop_Poblacion'] = p['Prop_SE'] * p['Prop_Prov']
p = p[['sexo','Grupo_Edad','Provincia','Prop_Poblacion']]
muestra = (
    df.groupby(['Ventana','sexo','Grupo_Edad','estrato'])
      .size()
      .reset_index(name='N_muestra')
)
muestra['Prop_Muestra'] = muestra.groupby('Ventana')['N_muestra'].transform(lambda x: x / x.sum())
ponderacion = pd.merge(
    muestra,
    p,
    left_on=['sexo','Grupo_Edad','estrato'],
    right_on=['sexo','Grupo_Edad','Provincia'],
    how='left'
)
ponderacion['Peso'] = ponderacion['Prop_Poblacion'] / ponderacion['Prop_Muestra']
df = df.merge(
    ponderacion[['Ventana','sexo','Grupo_Edad','estrato','Peso']],
    on=['Ventana','sexo','Grupo_Edad','estrato'],
    how='left'
)
df

#%%
#Sexto Paso: ANALIZAR LA EVOLUCIÓN DE LA INTENCIÓN DE VOTO A LO LARGO DEL TIEMPO
df['Imagen_Ponderada'] = df['Peso'] * df['imagen_del_candidato']
tracking_imagen = (
    df.groupby('Ventana')
      .apply(lambda g: g['Imagen_Ponderada'].sum() / g['Peso'].sum())
      .reset_index(name='trackeo')
)
tracking_imagen

# %%
#Séptimo Paso: Graficar la evolución de la intención de voto
plt.figure(figsize=(10,5))
plt.plot(tracking_imagen['Ventana'], tracking_imagen['trackeo'], marker='o')
plt.xlabel('Ventana', fontsize = 10)
plt.ylabel('Imagen promedio', fontsize = 10)
plt.title('Evolución de la imagen del candidato', fontsize = 16)
plt.tight_layout()
plt.show()

# %%
#Octavo Paso: Analizar la evolución de la intención de voto del candidato
if (conteo_por_dia >= 750).all():
    df['Ventana'] = df['fecha'].dt.to_period('D')
else:
    df['Ventana'] = df['fecha'].dt.to_period('W')
candidatos = df['voto'].unique().tolist()
for c in candidatos:
    df[f'vota_{c}'] = (df['voto'] == c).astype(int)
    df[f'vota_{c}_ponderada'] = df[f'vota_{c}'] * df['Peso']
tracking_voto = (
    df.groupby('Ventana')
      .apply(lambda g: pd.Series({
          f"Vota_{c}": (g[f'vota_{c}_ponderada'].sum() / g['Peso'].sum()) * 100
          for c in candidatos
      }))
      .reset_index()
)
tracking_voto.round(1)

#%%
#Noveno Paso: graficar la evolución de la intención de voto
tracking_voto.plot(figsize=(12,5))
plt.xlabel('Ventana', fontsize = 10)
plt.ylabel('Intención de voto (%)', fontsize = 10)
plt.title('Tracking de intención de voto ponderado', fontsize = 16)
plt.grid(alpha=0.3)
plt.legend(title="Candidato")
plt.show()

